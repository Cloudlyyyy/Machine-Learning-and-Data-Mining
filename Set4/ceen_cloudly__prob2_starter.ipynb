{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fzZb8grE78U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import urllib.request\n",
        "import sklearn\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG06KHdyQKMN",
        "outputId": "dfbcf7cd-6037-4974-939c-9854d1cf1b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n",
            "0.14.1+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvPFMow_NNry"
      },
      "source": [
        "# Part A: Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7m_kQfspQJNf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "866f0061-3304-4fa5-ce52-b194d8eeb1e0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        Unnamed: 0 start_date  cdc_case_earliest_dt   cdc_report_dt  \\\n",
              "0                0 2020-01-20                  203.0          769.0   \n",
              "39              39 2020-01-20                  648.0          653.0   \n",
              "49              49 2020-01-20                  315.0          470.0   \n",
              "60              60 2020-01-20                  754.0          771.0   \n",
              "65              65 2020-01-20                  257.0          273.0   \n",
              "...            ...        ...                    ...            ...   \n",
              "799878      799878 2020-01-20                  728.0          728.0   \n",
              "799882      799882 2020-01-20                  677.0          688.0   \n",
              "799894      799894 2020-01-20                  352.0          352.0   \n",
              "799938      799938 2020-01-20                  627.0          627.0   \n",
              "799978      799978 2020-01-20                  179.0          766.0   \n",
              "\n",
              "        pos_spec_dt  onset_dt  current_status  sex  age_group  \\\n",
              "0             207.0     203.0               0    0          0   \n",
              "39            651.0     648.0               0    1          1   \n",
              "49            317.0     315.0               0    1          1   \n",
              "60            755.0     754.0               0    0          2   \n",
              "65            266.0     257.0               0    0          0   \n",
              "...             ...       ...             ...  ...        ...   \n",
              "799878        728.0     728.0               0    1          3   \n",
              "799882        679.0     677.0               0    1          2   \n",
              "799894        353.0     352.0               0    0          4   \n",
              "799938        639.0     627.0               0    1          4   \n",
              "799978        176.0     179.0               0    0          6   \n",
              "\n",
              "        race_ethnicity_combined  hosp_yn  icu_yn  death_yn  medcond_yn  \n",
              "0                             0        0       0         0           0  \n",
              "39                            1        0       1         0           1  \n",
              "49                            2        1       1         0           2  \n",
              "60                            1        1       1         0           2  \n",
              "65                            0        0       1         0           1  \n",
              "...                         ...      ...     ...       ...         ...  \n",
              "799878                        1        2       2         0           3  \n",
              "799882                        1        0       1         0           2  \n",
              "799894                        1        0       0         0           0  \n",
              "799938                        3        0       0         0           1  \n",
              "799978                        2        0       0         0           0  \n",
              "\n",
              "[59371 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6be26991-b181-470e-b6ae-8a2eb3aef587\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>start_date</th>\n",
              "      <th>cdc_case_earliest_dt</th>\n",
              "      <th>cdc_report_dt</th>\n",
              "      <th>pos_spec_dt</th>\n",
              "      <th>onset_dt</th>\n",
              "      <th>current_status</th>\n",
              "      <th>sex</th>\n",
              "      <th>age_group</th>\n",
              "      <th>race_ethnicity_combined</th>\n",
              "      <th>hosp_yn</th>\n",
              "      <th>icu_yn</th>\n",
              "      <th>death_yn</th>\n",
              "      <th>medcond_yn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2020-01-20</td>\n",
              "      <td>203.0</td>\n",
              "      <td>769.0</td>\n",
              "      <td>207.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>39</td>\n",
              "      <td>2020-01-20</td>\n",
              "      <td>648.0</td>\n",
              "      <td>653.0</td>\n",
              "      <td>651.0</td>\n",
              "      <td>648.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>49</td>\n",
              "      <td>2020-01-20</td>\n",
              "      <td>315.0</td>\n",
              "      <td>470.0</td>\n",
              "      <td>317.0</td>\n",
              "      <td>315.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>60</td>\n",
              "      <td>2020-01-20</td>\n",
              "      <td>754.0</td>\n",
              "      <td>771.0</td>\n",
              "      <td>755.0</td>\n",
              "      <td>754.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>65</td>\n",
              "      <td>2020-01-20</td>\n",
              "      <td>257.0</td>\n",
              "      <td>273.0</td>\n",
              "      <td>266.0</td>\n",
              "      <td>257.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799878</th>\n",
              "      <td>799878</td>\n",
              "      <td>2020-01-20</td>\n",
              "      <td>728.0</td>\n",
              "      <td>728.0</td>\n",
              "      <td>728.0</td>\n",
              "      <td>728.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799882</th>\n",
              "      <td>799882</td>\n",
              "      <td>2020-01-20</td>\n",
              "      <td>677.0</td>\n",
              "      <td>688.0</td>\n",
              "      <td>679.0</td>\n",
              "      <td>677.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799894</th>\n",
              "      <td>799894</td>\n",
              "      <td>2020-01-20</td>\n",
              "      <td>352.0</td>\n",
              "      <td>352.0</td>\n",
              "      <td>353.0</td>\n",
              "      <td>352.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799938</th>\n",
              "      <td>799938</td>\n",
              "      <td>2020-01-20</td>\n",
              "      <td>627.0</td>\n",
              "      <td>627.0</td>\n",
              "      <td>639.0</td>\n",
              "      <td>627.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799978</th>\n",
              "      <td>799978</td>\n",
              "      <td>2020-01-20</td>\n",
              "      <td>179.0</td>\n",
              "      <td>766.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59371 rows Ã— 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6be26991-b181-470e-b6ae-8a2eb3aef587')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6be26991-b181-470e-b6ae-8a2eb3aef587 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6be26991-b181-470e-b6ae-8a2eb3aef587');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# data preprocessing\n",
        "\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/emiletimothy/Caltech-CS155-2023/main/set4/data/COVID-19_Case_Surveillance_Public_Use_Data_Subset.csv\", \"COVID-19_Case_Surveillance_Public_Use_Data_Subset.csv\")\n",
        "df = pd.read_csv(\"COVID-19_Case_Surveillance_Public_Use_Data_Subset.csv\")\n",
        "\n",
        "# TODO: preprocess df\n",
        "\n",
        "# convert all death_yn with missing/unknown to NaN\n",
        "\n",
        "df['death_yn'] = df['death_yn'].replace(['Missing'], np.NAN)\n",
        "df['death_yn'] = df['death_yn'].replace(['Unknown'], np.NAN)\n",
        "\n",
        "# convert date strings to date time using to_datetime\n",
        "\n",
        "df['cdc_case_earliest_dt '] = pd.to_datetime(df['cdc_case_earliest_dt '])\n",
        "df['cdc_report_dt'] = pd.to_datetime(df['cdc_report_dt'])\n",
        "df['pos_spec_dt'] = pd.to_datetime(df['pos_spec_dt'])\n",
        "df['onset_dt'] = pd.to_datetime(df['onset_dt'])\n",
        "\n",
        "# add column of start date in front of df\n",
        "\n",
        "df = df.assign(start_date = ['2020/01/20'] * len(df))\n",
        "first = df.pop('start_date')\n",
        "df.insert(1, 'start_date', first)\n",
        "\n",
        "# convert and subtract from all dates\n",
        "\n",
        "df['start_date'] = pd.to_datetime(df['start_date'])\n",
        "\n",
        "df['cdc_case_earliest_dt '] = (df['cdc_case_earliest_dt '] - df['start_date']) / np.timedelta64(1,'D')\n",
        "df['cdc_report_dt'] = (df['cdc_report_dt'] - df['start_date']) / np.timedelta64(1,'D')\n",
        "df['pos_spec_dt'] = (df['pos_spec_dt'] - df['start_date']) / np.timedelta64(1,'D')\n",
        "df['onset_dt'] = (df['onset_dt'] - df['start_date']) / np.timedelta64(1,'D')\n",
        "\n",
        "# drop rows with NaN values in death_yn pos_spec_dt onset_d\n",
        "\n",
        "df = df.dropna(subset = ['death_yn'])\n",
        "df = df.dropna(subset = ['pos_spec_dt'])\n",
        "df = df.dropna(subset = ['onset_dt'])\n",
        "\n",
        "# factorize columns\n",
        "\n",
        "df[['current_status', 'sex', 'age_group', 'race_ethnicity_combined', 'hosp_yn', 'icu_yn', 'death_yn', 'medcond_yn']] = df[['current_status', 'sex', 'age_group', 'race_ethnicity_combined', 'hosp_yn', 'icu_yn', 'death_yn', 'medcond_yn']].apply(lambda x: pd.factorize(x)[0])\n",
        "\n",
        "display(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Wn-AQp6FDpM"
      },
      "outputs": [],
      "source": [
        "# TODO: make sure your data can be converted to torch tensors\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(df.iloc[:,[4,5,6,7,8,9,10,11,13]], df['death_yn'], test_size = 0.2)\n",
        "\n",
        "# normalize training and data\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit(train_X.iloc[:,[4,5]])\n",
        "\n",
        "train_X.iloc[:,[4,5]] = scaler.transform(train_X.iloc[:,[4,5]])\n",
        "test_X.iloc[:,[4,5]] = scaler.transform(test_X.iloc[:,[4,5]])\n",
        "\n",
        "# make datasets and dataloaders\n",
        "\n",
        "tensor_train_X = torch.Tensor(train_X.to_numpy())\n",
        "tensor_train_y = torch.Tensor(train_y.to_numpy()).type(torch.LongTensor)\n",
        "tensor_test_X = torch.Tensor(test_X.to_numpy())\n",
        "tensor_test_y = torch.Tensor(test_y.to_numpy()).type(torch.LongTensor)\n",
        "\n",
        "train_dataset = TensorDataset(tensor_train_X, tensor_train_y)\n",
        "test_dataset = TensorDataset(tensor_test_X, tensor_test_y)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ccx89l3btfq4"
      },
      "source": [
        "# Part B: Linear Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aICcIvNtNGk2"
      },
      "source": [
        "## Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtMSBKxdFfjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d03951a8-e3ca-43f2-aafc-fcab3e23cac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=9, out_features=5, bias=True)\n",
            "  (1): Softmax(dim=None)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# TODO: Make your model, optmizer, and loss function here.\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(9, 5),\n",
        "    nn.Softmax()\n",
        ")\n",
        "print(model)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKl5Tm2TNXxc"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-RVMsj0NaN7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "140bdf3b-54e7-4abb-e3ae-1c70c872eb1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1  Loss: 0.9048\n",
            "Train Epoch: 2  Loss: 0.9048\n",
            "Train Epoch: 3  Loss: 0.9048\n",
            "Train Epoch: 4  Loss: 0.9048\n",
            "Train Epoch: 5  Loss: 0.9048\n",
            "Train Epoch: 6  Loss: 0.9048\n",
            "Train Epoch: 7  Loss: 0.9048\n",
            "Train Epoch: 8  Loss: 0.9048\n",
            "Train Epoch: 9  Loss: 1.0298\n",
            "Train Epoch: 10  Loss: 0.9048\n"
          ]
        }
      ],
      "source": [
        "# Some layers, such as Dropout, behave differently during training\n",
        "\n",
        "model.train()\n",
        "\n",
        "# TODO: Write your training loop here.\n",
        "\n",
        "for epoch in range(10):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Erase accumulated gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(output, target)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Weight update\n",
        "        optimizer.step()\n",
        "\n",
        "    # Track loss each epoch\n",
        "    print('Train Epoch: %d  Loss: %.4f' % (epoch + 1,  loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZCNGh5mNbE0"
      },
      "source": [
        "## Testing Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SxnJ3eHNfgb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bc0fafb-0d44-4e55-bb88-1cc3ea98d3ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0291, Accuracy: 11581/11875 (97.5242)\n"
          ]
        }
      ],
      "source": [
        "# Putting layers like Dropout into evaluation mode\n",
        "model.eval()\n",
        "\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "\n",
        "# Turning off automatic differentiation\n",
        "with torch.no_grad():\n",
        "    # TODO: Write test loop here.\n",
        "    for data, target in test_loader:\n",
        "        output = model(data)\n",
        "        test_loss += loss_fn(output, target).item()  # Sum up batch loss\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max class score\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "\n",
        "# TODO: Show results.\n",
        "print('Test set: Average loss: %.4f, Accuracy: %d/%d (%.4f)' % (test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf9UHC-kZ25f"
      },
      "source": [
        "## Weight Matrix Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBXDC10mRNto",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "69568290-3b0a-42ca-f897-10338a0c7b35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe8e1d07070>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "weights = model.state_dict()['0.weight']\n",
        "sns.heatmap(weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91H6-NUVZ8Gd"
      },
      "source": [
        "# Part C: 2-Layer Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUd6CAB-WebM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f740989-0884-4b4f-db51-33c48ceb4b33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=9, out_features=7, bias=True)\n",
            "  (1): Linear(in_features=7, out_features=5, bias=True)\n",
            "  (2): Softmax(dim=None)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# TODO: Repeat for 2-layer model\n",
        "\n",
        "model_2 = nn.Sequential(\n",
        "    nn.Linear(9, 7),\n",
        "    nn.Linear(7, 5),\n",
        "    nn.Softmax()\n",
        ")\n",
        "print(model_2)\n",
        "\n",
        "optimizer = torch.optim.Adam(model_2.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some layers, such as Dropout, behave differently during training\n",
        "\n",
        "model_2.train()\n",
        "\n",
        "# TODO: Write your training loop here.\n",
        "\n",
        "for epoch in range(10):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Erase accumulated gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model_2(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(output, target)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Weight update\n",
        "        optimizer.step()\n",
        "\n",
        "    # Track loss each epoch\n",
        "    print('Train Epoch: %d  Loss: %.4f' % (epoch + 1,  loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh87PKmeGToU",
        "outputId": "08059b65-5765-46f4-8373-4632ddd2b873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1  Loss: 0.9048\n",
            "Train Epoch: 2  Loss: 0.9048\n",
            "Train Epoch: 3  Loss: 0.9048\n",
            "Train Epoch: 4  Loss: 0.9048\n",
            "Train Epoch: 5  Loss: 0.9048\n",
            "Train Epoch: 6  Loss: 0.9048\n",
            "Train Epoch: 7  Loss: 0.9048\n",
            "Train Epoch: 8  Loss: 0.9048\n",
            "Train Epoch: 9  Loss: 1.0298\n",
            "Train Epoch: 10  Loss: 0.9048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting layers like Dropout into evaluation mode\n",
        "model_2.eval()\n",
        "\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "\n",
        "# Turning off automatic differentiation\n",
        "with torch.no_grad():\n",
        "    # TODO: Write test loop here.\n",
        "    for data, target in test_loader:\n",
        "        output = model_2(data)\n",
        "        test_loss += loss_fn(output, target).item()  # Sum up batch loss\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max class score\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "\n",
        "# TODO: Show results.\n",
        "print('Test set: Average loss: %.4f, Accuracy: %d/%d (%.4f)' % (test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgAQEhYsGcQE",
        "outputId": "200f9f05-5aa4-4fdf-ae13-16fd74a37d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0291, Accuracy: 11581/11875 (97.5242)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \n[Clang 13.0.1 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "4b5295d72cc8c3d140bbb6686d5919ce0ad0a523816efde1e1cd082b7d39dbc7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}